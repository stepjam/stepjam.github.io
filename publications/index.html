<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>publications | Stephen James</title> <meta name="author" content="Stephen James"> <meta name="description" content="For an up-to-date list, please see my Google Scholar."> <meta name="keywords" content="robotics, robot learing, stephen james, AI, ML"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="stepjam.github.io/publications/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Stephen James</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/group/">group</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications<span class="sr-only">(current)</span></a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">For an up-to-date list, please see my Google Scholar.</p> </header> <article> <div class="publications"> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/xie_lapp.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/xie_lapp.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/xie_lapp.gif-1400.webp"></source> <img src="/assets/img/publication_preview/xie_lapp.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="xie_lapp.gif" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="xie2023language" class="col-sm-8"> <div class="title">Language-conditioned path planning</div> <div class="author"> Amber Xie, Youngwoon Lee, Pieter Abbeel, and <em>Stephen James</em> </div> <div class="periodical"> <em>Conference on Robot Learning</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2308.16893.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/wang_speedco-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/wang_speedco-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/wang_speedco-1400.webp"></source> <img src="/assets/img/publication_preview/wang_speedco.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="wang_speedco.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="wang2023speed" class="col-sm-8"> <div class="title">Speed Co-Augmentation for Unsupervised Audio-Visual Pre-training</div> <div class="author"> Jiangliu Wang, Jianbo Jiao, Yibing Song, <em>Stephen James</em>, Zhan Tong, Chongjian Ge, Pieter Abbeel, and Yun-Hui Liu</div> <div class="periodical"> <em>arXiv preprint arXiv:2309.13942</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2309.13942.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/seo_mvmwm-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/seo_mvmwm-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/seo_mvmwm-1400.webp"></source> <img src="/assets/img/publication_preview/seo_mvmwm.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="seo_mvmwm.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="seo2023multi" class="col-sm-8"> <div class="title">Multi-view masked world models for visual robotic manipulation</div> <div class="author"> Younggyo Seo, Junsu Kim, <em>Stephen James</em>, Kimin Lee, Jinwoo Shin, and Pieter Abbeel</div> <div class="periodical"> <em>International Conference on Machine Learning</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2302.02408.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/adeniji_lamp-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/adeniji_lamp-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/adeniji_lamp-1400.webp"></source> <img src="/assets/img/publication_preview/adeniji_lamp.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="adeniji_lamp.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="adeniji2023language" class="col-sm-8"> <div class="title">Language reward modulation for pretraining reinforcement learning</div> <div class="author"> Ademi Adeniji, Amber Xie, Carmelo Sferrazza, Younggyo Seo, <em>Stephen James</em>, and Pieter Abbeel</div> <div class="periodical"> <em>arXiv preprint arXiv:2308.12270</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2308.12270.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/yan_teco.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/yan_teco.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/yan_teco.gif-1400.webp"></source> <img src="/assets/img/publication_preview/yan_teco.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="yan_teco.gif" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="yan2023temporally" class="col-sm-8"> <div class="title">Temporally consistent transformers for video generation</div> <div class="author"> Wilson Yan, Danijar Hafner, <em>Stephen James</em>, and Pieter Abbeel</div> <div class="periodical"> <em>International Conference on Machine Learning</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2210.02396.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/chen_stereopose-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/chen_stereopose-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/chen_stereopose-1400.webp"></source> <img src="/assets/img/publication_preview/chen_stereopose.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="chen_stereopose.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="chen2023stereopose" class="col-sm-8"> <div class="title">Stereopose: Category-level 6d transparent object pose estimation from stereo images via back-view nocs</div> <div class="author"> Kai Chen, <em>Stephen James</em>, Congying Sui, Yun-Hui Liu, Pieter Abbeel, and Qi Dou</div> <div class="periodical"> <em>IEEE International Conference on Robotics and Automation</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2211.01644.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/xie_sim2seg.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/xie_sim2seg.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/xie_sim2seg.gif-1400.webp"></source> <img src="/assets/img/publication_preview/xie_sim2seg.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="xie_sim2seg.gif" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="so2022sim" class="col-sm-8"> <div class="title">Sim-to-Real via Sim-to-Seg: End-to-end Off-road Autonomous Driving Without Real Data</div> <div class="author"> John So, Amber Xie, Sunggoo Jung, Jeffrey Edlund, Rohan Thakker, Ali Agha-mohammadi, Pieter Abbeel, and <em>Stephen James</em> </div> <div class="periodical"> <em>Conference on Robot Learning</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2210.14721.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/radosavovic_mvp-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/radosavovic_mvp-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/radosavovic_mvp-1400.webp"></source> <img src="/assets/img/publication_preview/radosavovic_mvp.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="radosavovic_mvp.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Radosavovic2022" class="col-sm-8"> <div class="title">Real-World Robot Learning with Masked Visual Pre-training</div> <div class="author"> Ilija Radosavovic, Tete Xiao, <em>Stephen James</em>, Pieter Abbeel, Jitendra Malik, and Trevor Darrell</div> <div class="periodical"> <em>Conference on Robot Learning</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2210.03109.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/seo_mwm.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/seo_mwm.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/seo_mwm.gif-1400.webp"></source> <img src="/assets/img/publication_preview/seo_mwm.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="seo_mwm.gif" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="seo2022masked" class="col-sm-8"> <div class="title">Masked World Models for Visual Control</div> <div class="author"> Younggyo Seo, Danijar Hafner, Hao Liu, Fangchen Liu, <em>Stephen James</em>, Kimin Lee, and Pieter Abbeel</div> <div class="periodical"> <em>Conference on Robot Learning</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2206.14244.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/seo_apv-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/seo_apv-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/seo_apv-1400.webp"></source> <img src="/assets/img/publication_preview/seo_apv.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="seo_apv.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="seo2022reinforcement" class="col-sm-8"> <div class="title">Reinforcement learning with action-free pre-training from videos</div> <div class="author"> Younggyo Seo, Kimin Lee, Stephen L James, and Pieter Abbeel</div> <div class="periodical"> <em>International Conference on Machine Learning</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2203.13880.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/yan_povt.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/yan_povt.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/yan_povt.gif-1400.webp"></source> <img src="/assets/img/publication_preview/yan_povt.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="yan_povt.gif" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="yan2022patch" class="col-sm-8"> <div class="title">Patch-based Object-centric Transformers for Efficient Video Generation</div> <div class="author"> Wilson Yan, Ryo Okumura, <em>Stephen James</em>, and Pieter Abbeel</div> <div class="periodical"> <em>arXiv preprint arXiv:2206.04003</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2206.04003.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/liu_auto_lambda-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/liu_auto_lambda-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/liu_auto_lambda-1400.webp"></source> <img src="/assets/img/publication_preview/liu_auto_lambda.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="liu_auto_lambda.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="liu2022auto" class="col-sm-8"> <div class="title">Auto-Lambda: Disentangling Dynamic Task Relationships</div> <div class="author"> Shikun Liu, <em>Stephen James</em>, Andrew J Davison, and Edward Johns</div> <div class="periodical"> <em>Transactions on Machine Learning Research</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2202.03091.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/zhao_fine_tuning_meta-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/zhao_fine_tuning_meta-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/zhao_fine_tuning_meta-1400.webp"></source> <img src="/assets/img/publication_preview/zhao_fine_tuning_meta.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="zhao_fine_tuning_meta.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="mandi2022effectiveness" class="col-sm-8"> <div class="title">On the Effectiveness of Fine-tuning Versus Meta-reinforcement Learning</div> <div class="author"> Zhao Mandi, Pieter Abbeel, and <em>Stephen James</em> </div> <div class="periodical"> <em>Conference on Neural Information Processing Systems</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2206.03271.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/james_c2f_te-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/james_c2f_te-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/james_c2f_te-1400.webp"></source> <img src="/assets/img/publication_preview/james_c2f_te.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="james_c2f_te.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="james2022coarse" class="col-sm-8"> <div class="title">Coarse-to-fine Q-attention with Tree Expansion</div> <div class="author"> <em>Stephen James</em>, and Pieter Abbeel</div> <div class="periodical"> <em>arXiv preprint arXiv:2204.12471</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2204.12471.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/james_c2f_lpr-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/james_c2f_lpr-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/james_c2f_lpr-1400.webp"></source> <img src="/assets/img/publication_preview/james_c2f_lpr.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="james_c2f_lpr.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="james2022coarsf" class="col-sm-8"> <div class="title">Coarse-to-Fine Q-attention with Learned Path Ranking</div> <div class="author"> <em>Stephen James</em>, and Pieter Abbeel</div> <div class="periodical"> <em>arXiv preprint arXiv:2204.01571</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2204.01571.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/wada_reorientbot.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/wada_reorientbot.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/wada_reorientbot.gif-1400.webp"></source> <img src="/assets/img/publication_preview/wada_reorientbot.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="wada_reorientbot.gif" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="wada2022reorientbot" class="col-sm-8"> <div class="title">ReorientBot: Learning Object Reorientation for Specific-Posed Placement</div> <div class="author"> Kentaro Wada, <em>Stephen James</em>, and Andrew J Davison</div> <div class="periodical"> <em>IEEE International Conference on Robotics and Automation</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2202.11092.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/wada_safepicking.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/wada_safepicking.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/wada_safepicking.gif-1400.webp"></source> <img src="/assets/img/publication_preview/wada_safepicking.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="wada_safepicking.gif" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="wada2022safepicking" class="col-sm-8"> <div class="title">SafePicking: Learning safe object extraction via object-level mapping</div> <div class="author"> Kentaro Wada, <em>Stephen James</em>, and Andrew J Davison</div> <div class="periodical"> <em>IEEE International Conference on Robotics and Automation</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2202.05832.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/chen_self_train_pose-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/chen_self_train_pose-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/chen_self_train_pose-1400.webp"></source> <img src="/assets/img/publication_preview/chen_self_train_pose.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="chen_self_train_pose.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="chen2022sim" class="col-sm-8"> <div class="title">Sim-to-Real 6D Object Pose Estimation via Iterative Self-training for Robotic Bin-picking</div> <div class="author"> Kai Chen, Rui Cao, <em>Stephen James</em>, Yichuan Li, Yun-Hui Liu, Pieter Abbeel, and Qi Dou</div> <div class="periodical"> <em>European Conference on Computer Vision</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2204.07049.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/seo_harp-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/seo_harp-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/seo_harp-1400.webp"></source> <img src="/assets/img/publication_preview/seo_harp.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="seo_harp.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="harp2022sim" class="col-sm-8"> <div class="title">HARP: Autoregressive Latent Video Prediction with High-Fidelity Image Generator</div> <div class="author"> Younggyo Seo, Kimin Lee, Fangchen Liu, <em>Stephen James</em>, and Pieter Abbeel</div> <div class="periodical"> <em>IEEE International Conference on Image Processing</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2209.07143.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/james_bing-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/james_bing-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/james_bing-1400.webp"></source> <img src="/assets/img/publication_preview/james_bing.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="james_bing.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="james2022bingham" class="col-sm-8"> <div class="title">Bingham Policy Parameterization for 3D Rotations in Reinforcement Learning</div> <div class="author"> <em>Stephen James</em>, and Pieter Abbeel</div> <div class="periodical"> <em>arXiv preprint arXiv:2202.03957</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2202.03957.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/james_c2f.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/james_c2f.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/james_c2f.gif-1400.webp"></source> <img src="/assets/img/publication_preview/james_c2f.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="james_c2f.gif" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="james2021coarse" class="col-sm-8"> <div class="title">Coarse-to-Fine Q-attention: Efficient Learning for Visual Robotic Manipulation via Discretisation</div> <div class="author"> <em>Stephen James</em>, Kentaro Wada, Tristan Laidlow, and Andrew J Davison</div> <div class="periodical"> <em>Conference on Computer Vision and Pattern Recognition</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2106.12534.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/james_qatt-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/james_qatt-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/james_qatt-1400.webp"></source> <img src="/assets/img/publication_preview/james_qatt.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="james_qatt.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="james2021q" class="col-sm-8"> <div class="title">Q-attention: Enabling Efficient Learning for Vision-based Robotic Manipulation</div> <div class="author"> <em>Stephen James</em>, and Andrew J Davison</div> <div class="periodical"> <em>IEEE Robotics and Automation Letters</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2105.14829.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/lenton_esm-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/lenton_esm-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/lenton_esm-1400.webp"></source> <img src="/assets/img/publication_preview/lenton_esm.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="lenton_esm.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="lenton2020end" class="col-sm-8"> <div class="title">End-to-End Egospheric Spatial Memory</div> <div class="author"> Daniel James Lenton, <em>Stephen James</em>, Ronald Clark, and Andrew Davison</div> <div class="periodical"> <em>International Conference on Learning Representations</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2102.07764.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/landgraf_simstack.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/landgraf_simstack.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/landgraf_simstack.gif-1400.webp"></source> <img src="/assets/img/publication_preview/landgraf_simstack.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="landgraf_simstack.gif" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="landgraf2021simstack" class="col-sm-8"> <div class="title">SIMstack: A Generative Shape and Instance Model for Unordered Object Stacks</div> <div class="author"> Zoe Landgraf, Raluca Scona, Tristan Laidlow, <em>Stephen James</em>, Stefan Leutenegger, and Andrew J Davison</div> <div class="periodical"> <em>IEEE International Conference on Computer Vision</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2103.16442.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/toma_wpn-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/toma_wpn-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/toma_wpn-1400.webp"></source> <img src="/assets/img/publication_preview/toma_wpn.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="toma_wpn.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="toma2021waypoint" class="col-sm-8"> <div class="title">Waypoint Planning Networks</div> <div class="author"> Alexandru-Iosif Toma, Hussein Ali Jaafar, Hao-Ya Hsueh, <em>Stephen James</em>, Daniel Lenton, Ronald Clark, and Sajad Saeedi</div> <div class="periodical"> <em>Conference on Robots and Vision</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2105.00312.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> </ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/wada_morefusion.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/wada_morefusion.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/wada_morefusion.gif-1400.webp"></source> <img src="/assets/img/publication_preview/wada_morefusion.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="wada_morefusion.gif" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="wada2020morefusion" class="col-sm-8"> <div class="title">MoreFusion: Multi-object Reasoning for 6D Pose Estimation from Volumetric Fusion</div> <div class="author"> Kentaro Wada, Edgar Sucar, <em>Stephen James</em>, Daniel Lenton, and Andrew J Davison</div> <div class="periodical"> <em>Conference on Computer Vision and Pattern Recognition</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2004.04336.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/james_rlbench-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/james_rlbench-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/james_rlbench-1400.webp"></source> <img src="/assets/img/publication_preview/james_rlbench.jpg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="james_rlbench.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="james2020rlbench" class="col-sm-8"> <div class="title">RLBench: The Robot Learning Benchmark &amp; Learning Environment</div> <div class="author"> <em>Stephen James</em>, Zicong Ma, David Rovick Arrojo, and Andrew J Davison</div> <div class="periodical"> <em>IEEE Robotics and Automation Letters</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/1909.12271.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/bonardi_humans-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/bonardi_humans-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/bonardi_humans-1400.webp"></source> <img src="/assets/img/publication_preview/bonardi_humans.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="bonardi_humans.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="bonardi2019learning" class="col-sm-8"> <div class="title">Learning One-Shot Imitation from Humans without Humans</div> <div class="author"> Alessandro Bonardi, <em>Stephen James</em>, and Andrew J Davison</div> <div class="periodical"> <em>IEEE Robotics and Automation Letters</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/1911.01103.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> </ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/james_pyrep-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/james_pyrep-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/james_pyrep-1400.webp"></source> <img src="/assets/img/publication_preview/james_pyrep.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="james_pyrep.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="james2019pyrep" class="col-sm-8"> <div class="title">Pyrep: Bringing V-Rep to Deep Robot Learning</div> <div class="author"> <em>Stephen James</em>, Marc Freese, and Andrew J Davison</div> <div class="periodical"> <em>arXiv preprint arXiv:1906.11176</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/1906.11176.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/james_rcan.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/james_rcan.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/james_rcan.gif-1400.webp"></source> <img src="/assets/img/publication_preview/james_rcan.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="james_rcan.gif" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="james2019sim" class="col-sm-8"> <div class="title">Sim-to-Real via Sim-to-Sim: Data-efficient Robotic Grasping via Randomized-to-Canonical Adaptation Networks</div> <div class="author"> <em>Stephen James</em>, Paul Wohlhart, Mrinal Kalakrishnan, Dmitry Kalashnikov, Alex Irpan, Julian Ibarz, Sergey Levine, Raia Hadsell, and Konstantinos Bousmalis</div> <div class="periodical"> <em>Conference on Computer Vision and Pattern Recognition</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/1812.07252.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> </ol> <h2 class="bibliography">2018</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/james_tecnets-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/james_tecnets-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/james_tecnets-1400.webp"></source> <img src="/assets/img/publication_preview/james_tecnets.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="james_tecnets.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="james2018task" class="col-sm-8"> <div class="title">Task-Embedded Control Networks for Few-Shot Imitation Learning</div> <div class="author"> <em>Stephen James</em>, Michael Bloesch, and Andrew J Davison</div> <div class="periodical"> <em>Conference on Robot Learning</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/1810.03237.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/matas_sim2realcloth.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/matas_sim2realcloth.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/matas_sim2realcloth.gif-1400.webp"></source> <img src="/assets/img/publication_preview/matas_sim2realcloth.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="matas_sim2realcloth.gif" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="matas2018sim" class="col-sm-8"> <div class="title">Sim-to-Real Reinforcement Learning for Deformable Object Manipulation</div> <div class="author"> Jan Matas, <em>Stephen James</em>, and Andrew J Davison</div> <div class="periodical"> <em>Conference on Robot Learning</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/1806.07851.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> </ol> <h2 class="bibliography">2017</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/james_dr.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/james_dr.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/james_dr.gif-1400.webp"></source> <img src="/assets/img/publication_preview/james_dr.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="james_dr.gif" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="james2017transferring" class="col-sm-8"> <div class="title">Transferring End-to-End Visuomotor Control from Simulation to Real World for a Multi-Stage Task</div> <div class="author"> <em>Stephen James</em>, Andrew J Davison, and Edward Johns</div> <div class="periodical"> <em>Conference on Robot Learning</em>, 2017 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/1707.02267.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li></ol> <h2 class="bibliography">2016</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/james_deepq-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/james_deepq-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/james_deepq-1400.webp"></source> <img src="/assets/img/publication_preview/james_deepq.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="james_deepq.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="james20163d" class="col-sm-8"> <div class="title">3D Simulation for Robot Arm Control with Deep Q-Learning</div> <div class="author"> <em>Stephen James</em>, and Edward Johns</div> <div class="periodical"> <em>NeurIPS 2016 Workshop (Deep Learning for Action and Interaction)</em>, 2016 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/1609.03759.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Stephen James. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?07b8786bab9b4abe90d10e61f7d12ff7" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>